// Package hubstorago provides an interface for interacting with a subset
// of the Scrapinghub API.
package hubstorago

import (
	"bytes"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"strings"
)

// defaultEndpoint represents the host where Hubstorage is running.
const defaultEndpoint = "https://storage.scrapinghub.com"

// Version is used to set the User-Agent header in reqests.
const Version = "0.1"

// A Client holds the minimum required information for making requests.
type Client struct {
	BaseUrl    string
	AuthKey    string
	HTTPClient http.Client
}

// urlJoin assembles the URL using the given parameters.
func (c *Client) urlJoin(parts []string) string {
	s := []string{}
	base := strings.Trim(c.BaseUrl, "/")
	if base == "" {
		base = defaultEndpoint
	}
	for i := 0; i < len(parts); i++ {
		if part := strings.Trim(parts[i], "/"); part != "" {
			s = append(s, part)
		}
	}
	url := append([]string{base}, s...)
	return strings.Join(url, "/")
}

// request fetches data from Hubstorage and stores the return in out.
// It speaks JSON only. If something goes wrong, the it passes down the error.
func (c *Client) request(method, url string, in []byte, out interface{}) error {
	b := new(bytes.Buffer)
	req, err := http.NewRequest(method, url, bytes.NewBuffer(in))
	if err != nil {
		return err
	}
	req.SetBasicAuth(c.AuthKey, "")
	req.Header.Add("Accept", "application/json")
	req.Header.Set("User-Agent", fmt.Sprintf("github.com/bertinatto/hubstorago (version %s)", Version))
	resp, err := c.HTTPClient.Do(req)
	defer resp.Body.Close()
	if err != nil {
		return err
	}
	if resp.StatusCode != http.StatusOK {
		return &ErrorHttpBadStatus{Code: resp.StatusCode}
	}
	if _, err := io.Copy(b, resp.Body); err != nil {
		return err
	}
	if err := json.NewDecoder(b).Decode(out); err != nil {
		return &ErrorJsonBadResponse{Body: err.Error()}
	}
	return nil
}

// GetCollectionsKey returns the value for k.
func (c *Client) GetCollectionsKey(pid, typeStore, name, k string) (*CollectionsData, error) {
	var d CollectionsData
	url := c.urlJoin([]string{"collections", pid, typeStore, name, k})
	if err := c.request("GET", url, nil, &d); err != nil {
		return nil, err
	}
	return &d, nil

}

// SetCollectionsKey sets the value for k.
func (c *Client) SetCollectionsKey(pid, typeStore, name, k, v string) error {
	entry := collectionEntry{
		Key:   k,
		Value: v}
	b := new(bytes.Buffer)
	if err := json.NewEncoder(b).Encode(entry); err != nil {
		return err
	}
	url := c.urlJoin([]string{"collections", pid, typeStore, name})
	return c.request("POST", url, b.Bytes(), nil)
}

// Items returns the items collected in jobkey.
// jobkey can be either a job or a project key.
func (c *Client) Items(jobkey string) (*interface{}, error) {
	var d interface{}
	url := c.urlJoin([]string{"items", jobkey})
	if err := c.request("GET", url, nil, &d); err != nil {
		return nil, err
	}
	return &d, nil
}

// Logs returns the logs generated by the spider while running.
// jobkey can be either a job or a project key.
func (c *Client) Logs(jobkey string) (*LogsData, error) {
	var d LogsData
	url := c.urlJoin([]string{"logs", jobkey})
	if err := c.request("GET", url, nil, &d); err != nil {
		return nil, err
	}
	return &d, nil
}

// Requests returns the requests made by the spider that ran in the given
// jobkey. jobkey can be either a job or a project key.
func (c *Client) Requests(jobkey string) (*RequestsData, error) {
	var d RequestsData
	url := c.urlJoin([]string{"requests", jobkey})
	if err := c.request("GET", url, nil, &d); err != nil {
		return nil, err
	}
	return &d, nil
}

// JobQ returns the list of jobs for project_id.
// Returns jobs from all queues.
func (c *Client) JobQ(project_id string) (*JobQData, error) {
	var d JobQData
	url := c.urlJoin([]string{"jobq", project_id, "list"})
	if err := c.request("GET", url, nil, &d); err != nil {
		return nil, err
	}
	return &d, nil
}
